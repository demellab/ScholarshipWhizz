{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9132fc85-07b6-4963-bdff-657d24bda219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa7e6e3-ebb7-4cc9-b5ee-7e7d4477d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cbc90f-f5d2-4195-a9aa-2b7d81fd395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d848340-db5e-4eb2-a15d-4721f83596ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded profile for: abira\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "def load_profile(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Example: replace with the user’s actual JSON path\n",
    "PROFILE = load_profile(\"profiles/user1.json\")\n",
    "print(\"Loaded profile for:\", PROFILE.get(\"user_id\", \"unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d789901-c189-4e32-b7e5-e6c5bfdd8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"scholarship_whizz_db.csv\"  # adjust if needed\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def normalize_level(degrees_value) -> str:\n",
    "    \"\"\"Map degree(s) text to one of: undergrad / grad / both.\"\"\"\n",
    "    s = str(degrees_value).lower()\n",
    "    grad_keys = [\"grad\", \"graduate\", \"master\", \"m.sc\", \"ms\", \"m.tech\", \"phd\", \"doctoral\", \"postgrad\", \"post-graduate\"]\n",
    "    ug_keys   = [\"undergrad\", \"undergraduate\", \"bachelor\", \"b.sc\", \"btech\", \"ba\", \"bcom\", \"b.eng\", \"b.engg\"]\n",
    "\n",
    "    is_grad = any(k in s for k in grad_keys)\n",
    "    is_ug   = any(k in s for k in ug_keys)\n",
    "\n",
    "    if is_grad and is_ug: return \"both\"\n",
    "    if is_grad:           return \"grad\"\n",
    "    if is_ug:             return \"undergrad\"\n",
    "    return \"both\"\n",
    "    \n",
    "def build_vectorstore_from_scholarships(csv_path=CSV_PATH):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Must match your headers exactly\n",
    "    required = [\"Scholarship Name\", \"Provider\", \"Amount\", \"Closing Date\", \"Degree(s)\", \"Status\", \"Link\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "    # NEW: derive normalized level\n",
    "    df[\"level_norm\"] = df[\"Degree(s)\"].apply(normalize_level)\n",
    "\n",
    "    docs = []\n",
    "    for i, row in df.iterrows():\n",
    "        content = (\n",
    "            f\"Scholarship Name: {row['Scholarship Name']}\\n\"\n",
    "            f\"Provider: {row['Provider']}\\n\"\n",
    "            f\"Amount: {row['Amount']}\\n\"\n",
    "            f\"Closing Date: {row['Closing Date']}\\n\"\n",
    "            f\"Degree(s): {row['Degree(s)']}\\n\"\n",
    "            f\"Status: {row['Status']}\\n\"\n",
    "            f\"Link: {row['Link']}\"\n",
    "        )\n",
    "        docs.append(Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"row\": int(i),\n",
    "                \"name\": row[\"Scholarship Name\"],\n",
    "                \"provider\": row[\"Provider\"],\n",
    "                \"closing_date\": row[\"Closing Date\"],\n",
    "                \"degree\": row[\"Degree(s)\"],\n",
    "                \"level\": row[\"level_norm\"],            # NEW: used for UG/Grad filter\n",
    "                \"link\": row[\"Link\"],\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    vs = Chroma.from_documents(\n",
    "        chunks,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"scholarship_whizz_db.csv\",\n",
    "        # persist_directory=\"./chroma_scholarships\"\n",
    "    )\n",
    "    return vs\n",
    "\n",
    "# Build once (or rebuild if CSV changed)\n",
    "vectorstore = build_vectorstore_from_scholarships()\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf7f6769-b20d-4832-964c-d9c0feb7e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"http://research-ai.tail69783d.ts.net:8001/v1\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0,\n",
    "    max_completion_tokens=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba0fbd9a-3b37-4d3f-88a7-0b9d3ed01e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simple v1 user setting\n",
    "# USER_LEVEL = \"undergrad\"   # or \"grad\". Later: set from Google Forms.\n",
    "\n",
    "# def set_user_level(level: str):\n",
    "#     global USER_LEVEL\n",
    "#     level = level.strip().lower()\n",
    "#     assert level in {\"undergrad\", \"grad\"}, \"level must be 'undergrad' or 'grad'\"\n",
    "#     USER_LEVEL = level\n",
    "#     print(\"User level set to:\", USER_LEVEL)\n",
    "\n",
    "# @tool\n",
    "# def retrieve_context(query: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Retrieve relevant scholarships from the CSV index, filtered by USER_LEVEL.\n",
    "#     \"\"\"\n",
    "#     results = retriever.invoke(query)\n",
    "\n",
    "#     def match_level(md):\n",
    "#         lvl = md.get(\"level\", \"both\")\n",
    "#         return (lvl == USER_LEVEL) or (lvl == \"both\")\n",
    "\n",
    "#     filtered = [d for d in results if match_level(d.metadata)] or results\n",
    "\n",
    "#     lines = []\n",
    "#     for doc in filtered[:5]:\n",
    "#         md = doc.metadata\n",
    "#         # Extract Amount nicely\n",
    "#         amt = \"-\"\n",
    "#         if \"Amount:\" in doc.page_content:\n",
    "#             try:\n",
    "#                 amt = doc.page_content.split(\"Amount: \")[1].splitlines()[0]\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "#         lines.append(\n",
    "#             f\"- {md.get('name','(no name)')} | Level: {md.get('level','both')} | Provider: {md.get('provider','-')} | \"\n",
    "#             f\"Amount: {amt} | Closing: {md.get('closing_date','-')} | Degree(s): {md.get('degree','-')} | Link: {md.get('link','-')}\"\n",
    "#         )\n",
    "#     return \"\\n\".join(lines) if lines else \"No matching scholarships found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6757b282-23e3-4c99-83d6-4d4fe2720bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "def _match_level(md_level: str, user_level: str) -> bool:\n",
    "    md_level = (md_level or \"both\").lower()\n",
    "    user_level = (user_level or \"undergrad\").lower()\n",
    "    return md_level == \"both\" or md_level == user_level\n",
    "\n",
    "def _profile_filter(md, profile: dict) -> bool:\n",
    "    ok = True\n",
    "    # level filter (required)\n",
    "    ok &= _match_level(md.get(\"level\"), profile.get(\"level\"))\n",
    "    # optional filters (add as your CSV supports them)\n",
    "    # if profile.get(\"country_of_study\"):\n",
    "    #     ok &= profile[\"country_of_study\"].lower() in str(md.get(\"country\",\"\")).lower() or md.get(\"country\") in (None, \"\", \"Any\")\n",
    "    # if profile.get(\"citizenship\"):\n",
    "    #     ok &= profile[\"citizenship\"].lower() in str(md.get(\"citizenship\",\"Any\")).lower() or md.get(\"citizenship\",\"Any\")==\"Any\"\n",
    "    # if profile.get(\"field\"):\n",
    "    #     ok &= profile[\"field\"].lower() in str(md.get(\"field\",\"\")).lower() or md.get(\"field\",\"\")==\"\" \n",
    "    return ok\n",
    "\n",
    "@tool\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant scholarships personalized by the loaded PROFILE.\"\"\"\n",
    "    # augment the query with profile keywords (if any)\n",
    "    kw = \" \".join(PROFILE.get(\"keywords\", []))\n",
    "    composite_query = f\"{query} {kw}\".strip()\n",
    "\n",
    "    candidates = retriever.invoke(composite_query)\n",
    "    filtered = [d for d in candidates if _profile_filter(d.metadata, PROFILE)] or candidates\n",
    "\n",
    "    lines = []\n",
    "    for doc in filtered[:5]:\n",
    "        md = doc.metadata\n",
    "        amt = \"-\"\n",
    "        if \"Amount:\" in doc.page_content:\n",
    "            try: amt = doc.page_content.split(\"Amount: \")[1].splitlines()[0]\n",
    "            except: pass\n",
    "        lines.append(\n",
    "            f\"- {md.get('name','(no name)')} | Level: {md.get('level','both')} | \"\n",
    "            f\"Amount: {amt} | Closing: {md.get('closing_date','-')} | Degree(s): {md.get('degree','-')} | Link: {md.get('link','-')}\"\n",
    "        )\n",
    "    return \"\\n\".join(lines) if lines else \"No matching scholarships found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706d8ccb-0d66-4a19-a4ca-1dbfa011aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal vLLM model connected and tools bound successfully\n"
     ]
    }
   ],
   "source": [
    "tools = [retrieve_context]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# bind tools to the model you just created\n",
    "model = model.bind_tools(tools)\n",
    "\n",
    "print(\"Internal vLLM model connected and tools bound successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1483ff0-f370-4301-8319-473d7c45112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if getattr(last_message, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d66b65-ec42-4ca8-9984-7817475b7f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x147ab9880>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a022073-61a3-4637-8c1b-d4b3eeafbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve_context]\n",
    "tool_node = ToolNode(tools)\n",
    "model = model.bind_tools(tools)  # reuse your existing ChatOpenAI instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f7c2047-b982-44e8-a3a7-1382601b2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointer = MemorySaver()\n",
    "# app = workflow.compile()\n",
    "\n",
    "# # thread_id must be a string when using MemorySaver\n",
    "# set_user_level(\"grad\")  # choose session persona\n",
    "# final_state = app.invoke(\n",
    "#     {\n",
    "#         \"messages\": [HumanMessage(content=\"print 5 scholarships in US\")],\n",
    "#         \"configurable\": {\"thread_id\": \"42\"}\n",
    "#     }\n",
    "# )\n",
    "# print(final_state[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd2c35c1-4811-4c61-bc9d-029af4b50b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "SYSTEM_TMPL = \"\"\"You are ScholarshipWhizz, a helpful assistant.\n",
    "\n",
    "User profile:\n",
    "- Level: {level}\n",
    "- Country of study: {country_of_study}\n",
    "- Citizenship: {citizenship}\n",
    "- Field: {field}\n",
    "- Deadline preference: {deadline_preference}\n",
    "- Keywords: {keywords}\n",
    "\n",
    "Use the retrieved scholarships below to propose the top options for this user.\n",
    "Be concise and include scholarship name, amount, deadline, and link.\n",
    "If something is missing, say so.\n",
    "Retrieved candidates:\n",
    "{retrieved}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_TMPL),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def build_prompt_inputs(question: str, retrieved_text: str, profile: dict):\n",
    "    return {\n",
    "        \"level\": profile.get(\"level\",\"\"),\n",
    "        \"country_of_study\": profile.get(\"country_of_study\",\"\"),\n",
    "        \"citizenship\": profile.get(\"citizenship\",\"\"),\n",
    "        \"field\": profile.get(\"field\",\"\"),\n",
    "        \"deadline_preference\": profile.get(\"deadline_preference\",\"\"),\n",
    "        \"keywords\": \", \".join(profile.get(\"keywords\", [])),\n",
    "        \"retrieved\": retrieved_text,\n",
    "        \"question\": question\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52e767a2-f914-4903-8ed5-97185998ffe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 2 scholarships that match your profile (undergrad, Canada, international, CS, women‑in‑tech focus, 2025 deadline)**  \n",
      "\n",
      "| Scholarship | Amount | Deadline | Link |\n",
      "|-------------|--------|----------|------|\n",
      "| **Canadian Women in STEM Scholarship** | **$10,000** | **30 Jan 2025** | [Apply here](https://universitystudy.ca/scholarship/14586/) |\n",
      "| **Clare E. and Anne Winterbottom Scholarship** | **$2,600** (2 × $1,300 terms) | **30 Apr 2025** | [Apply here](https://universitystudy.ca/scholarship/14169/) |\n",
      "\n",
      "**Why these are the best fit**\n",
      "\n",
      "* **Canadian Women in STEM Scholarship** – specifically targets women in STEM fields, offers a substantial award, and has a 2025 deadline that fits your timeline.  \n",
      "* **Clare E. and Anne Winterbottom Scholarship** – while not explicitly tech‑focused, it is open to all undergraduates, provides a decent award, and meets your deadline preference.\n",
      "\n",
      "**Note:** The other retrieved scholarships either lack a specified amount, have a later deadline (2026), or are geared toward non‑CS disciplines. No additional 2025‑eligible, CS‑focused scholarships were found in the current list.\n"
     ]
    }
   ],
   "source": [
    "retrieved = retrieve_context.invoke(\"Find scholarships about data/AI\")\n",
    "inputs = build_prompt_inputs(\"Recommend the best 3 for me\", retrieved, PROFILE)\n",
    "msg = prompt.invoke(inputs)\n",
    "resp = model.invoke(msg.to_messages())\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f406e-2f09-4df1-bdec-b69a3c81b62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
